---
title:	"Assignment 2"
author:	"Nishima Puri, Rhea Dsouza, Nirmal Umaria"
date:	"Feb'2023"
output: html_document:
---

```{r}
#Import Data
library(tidyverse)
library(lubridate)
library(data.table)
library(ggplot2)
```


#Importing data from The lcDataSample.csv file contains a sample of data on 3-year loans and saving it in a variable name.
```{r}
setwd("C:/Users/npuri8/Study Material/Sem2/Data Mining/Assignment 2")
lcdf <- read_csv('lcDataSample.csv')
```

############################################################################
#Explore the data
```{r}
#Question 2 - Data Exploration 
#a.(i) What is the proportion of defaults (‘charged off’ vs ‘fully paid’ loans) in the data?
lcdf %>% group_by(loan_status) %>% tally()

#Are there values for loan_status other than "Fully Paid' and "Charged Off"?  If so, remove them:
lcdf <- lcdf %>% filter(loan_status == "Fully Paid" | loan_status == "Charged Off")
lcdf %>% group_by(loan_status) %>% tally()
Prop_of_defaults <- lcdf %>% group_by(loan_status)%>%summarise(n=n())%>%mutate(freq=n/sum(n)*100)
setnames(Prop_of_defaults, old = c('loan_status','n'), new = c('loanStatus','totalCount'))
print(Prop_of_defaults)


#How does loan status vary by loan grade
lcdf %>% group_by(grade, loan_status) %>% tally()
#or, using table
table(lcdf$loan_status, lcdf$grade)


#How does loan status vary by loan grade
lcdf %>% group_by(loan_status, sub_grade) %>% tally()
#or, using table
table(lcdf$loan_status, lcdf$sub_grade)
```


############################################################################
```{r}
#Q2.a.(ii)
#What is the average interest rate in each grade? What about the average percentage (annual) return? 
lcdf %>% group_by(grade) %>% summarise(nLoans=n(), defaults=sum(loan_status=="Charged Off"), defaultRate=defaults/nLoans, avgInterest= mean(int_rate), stdInterest=sd(int_rate), avgLoanAMt=mean(loan_amnt), avgPmnt=mean(total_pymnt))

```




############################################################################
```{r}
#Q2.a.(iii)
#Data For loans fully paid - time-to-payoff  
head(lcdf[, c("last_pymnt_d", "issue_d")])
lcdf$last_pymnt_d<-paste(lcdf$last_pymnt_d, "-01", sep = "")

#Now we convert this character to a date type variable
lcdf$last_pymnt_d<-parse_date_time(lcdf$last_pymnt_d,  "myd")

head(lcdf[, c("last_pymnt_d", "issue_d")])

lcdf$actualTerm <- ifelse(lcdf$loan_status=="Fully Paid", as.duration(lcdf$issue_d  %--% lcdf$last_pymnt_d)/dyears(1), 3)

#Considering the actual term, actual return is
lcdf$actualReturn <- ifelse(lcdf$actualTerm>0, ((lcdf$total_pymnt-lcdf$funded_amnt)/lcdf$funded_amnt)*(1/lcdf$actualTerm)*100, 0)

#looking at the variable for first few rows of data
lcdf %>% group_by(grade) %>% select(loan_status, actualTerm, actualReturn) %>% head()


ggplot(lcdf, aes(x=actualTerm, y=grade)) + geom_boxplot(aes(fill=grade))+coord_flip()+labs(y="Grade", x = "Average Actual Term")

```





############################################################################
```{r}
#Q2.a.(iv)
#Examine actual returns from a loan, and relation with int_rate
#(for example, can one expect a 5%/year return from a loan with 5% int_rate?)


#do loans return an amount as may be expected from the int_rate ? 
lcdf %>% select(loan_status, int_rate, funded_amnt, total_pymnt) %>% head()


#calculate the annualized percentage return
lcdf$annRet <- ((lcdf$total_pymnt -lcdf$funded_amnt)/lcdf$funded_amnt)*(12/36)*100

#summarize by grade
lcdf %>% group_by(grade) %>% summarise(nLoans=n(), defaults=sum(loan_status=="Charged Off"), avgInterest= mean(int_rate), stdInterest=sd(int_rate), avgLoanAMt=mean(loan_amnt), avgPmnt=mean(total_pymnt), avgRet=mean(annRet), stdRet=sd(annRet), minRet=min(annRet), maxRet=max(annRet))

#summarize by sub-grade
lcdf %>% group_by(sub_grade) %>%dplyr::summarise(nLoans=n(), defaults=sum(loan_status=="Charged Off"), avgInterest= mean(int_rate), stdInterest=sd(int_rate), avgLoanAMt=mean(loan_amnt), avgPmnt=mean(total_pymnt), avgRet=mean(annRet), stdRet=sd(annRet), minRet=min(annRet), maxRet=max(annRet))

#Where do the negative numbers for minRet come from?
lcdf %>% select(loan_status, int_rate, funded_amnt, total_pymnt, annRet) %>% filter(annRet < 0) %>% head()

#are these all from 'Charged Off' loans?
lcdf %>% select(loan_status, int_rate, funded_amnt, total_pymnt, annRet) %>% filter(annRet < 0) %>% count(loan_status)

#Returns from 'Fully Paid' loans
lcdf %>% filter( loan_status == "Fully Paid") %>% group_by(grade) %>% summarise(nLoans=n(),  avgInterest= mean(int_rate), avgLoanAmt=mean(loan_amnt), avgPmnt=mean(total_pymnt), avgRet=mean(annRet),  minRet=min(annRet), maxRet=max(annRet))


#Similarly, returns from 'Charged Off" loans
lcdf %>% filter( loan_status == "Charged Off") %>% group_by(grade) %>% summarise(nLoans=n(), avgInterest= mean(int_rate), avgLoanAmt=mean(loan_amnt), avgPmnt=mean(total_pymnt), avgRet=mean(annRet),  minRet=min(annRet), maxRet=max(annRet))



#Boxplot for annual returns for Charged off loans
ggplot(lcdf %>% filter (loan_status == "Charged Off"), aes(x = annRet)) + geom_boxplot(aes(fill=grade))


#Boxplot for annual returns for Fully Paid loans
ggplot(lcdf %>% filter (loan_status == "Fully Paid"), aes(x = annRet)) + geom_boxplot(aes(fill=grade))


# For Fully Paid loans, is the average value of totRet what you'd expect, considering the average value for intRate?

#This summary can helps us to understand:
lcdf%>% group_by(loan_status) %>% summarise(  intRate=mean(int_rate), totRet=mean((total_pymnt-funded_amnt)/funded_amnt))

```




############################################################################

```{r}
#Q2.a.(vi)


#what are the different values, and how many examples are there for each value
lcdf %>% group_by(emp_length) %>% tally()

#convert emp_length to factor -- with factor levels ordered in a meaningful way
lcdf$emp_length <- factor(lcdf$emp_length, levels=c("n/a", "< 1 year","1 year","2 years", "3 years" ,  "4 years",   "5 years",   "6 years",   "7 years" ,  "8 years", "9 years", "10+ years" ))
# Note: we could have converted to factor by simply using 
#    x<-as.factor(lcdf$emp_length), 
#   but here the factor levels would be randomly arranged


#Do defaults vary by emp_length?
table(lcdf$loan_status, lcdf$emp_length)
  #this shows nujmber of Charged Off and Full Paid loans for different emp_length
#Can we calculate the proportion of Ca=harged Off loans for weach level of emp_length?
cc=table(lcdf$loan_status, lcdf$emp_length)
cc[1,]/(cc[1,] + cc[2,])   #dividing each element of the first row in cc by the sum of first and second row elements.


#Does the loan-grade assigned by LC vary by emp_length?
table(lcdf$purpose, lcdf$emp_length)
table(lcdf$grade, lcdf$emp_length)

#some addl summary by emp_length
lcdf %>% group_by(emp_length) %>% summarise(nLoans=n(), defaults=sum(loan_status=="Charged Off"), defaultRate=defaults/nLoans, avgIntRate=mean(int_rate),  avgLoanAmt=mean(loan_amnt),  avgActRet = mean(actualReturn), avgActTerm=mean(actualTerm))

summary(lcdf$annual_inc)
lcdf$annual_inc_cat <- cut(lcdf$annual_inc,
                           breaks = c(0, 43000, 60000, 72985, 88000, 8254000),
                           labels=c("very_low","low","medium",'high','very_high'))
table(lcdf$loan_status, lcdf$annual_inc_cat)
```




############################################################################

```{r}
#Q2.a.(vii)

#Derived attribute: proportion of satisfactory bankcard accounts 
lcdf$propSatisBankcardAccts <- ifelse(lcdf$num_bc_tl>0, lcdf$num_bc_sats/lcdf$num_bc_tl, 0)
 
#Another one - lets calculate the length of borrower's history with LC
#  i.e time between earliest_cr_line and issue_d
#  Look at these variables - you will notice that earliest_cr_line is read in as 'chr', we first convert it to date
#      and then subtract the two dates
lcdf$earliest_cr_line<-paste(lcdf$earliest_cr_line, "-01", sep = "")
lcdf$earliest_cr_line<-parse_date_time(lcdf$earliest_cr_line, "myd")

#lcdf$issue_d<-parse_date_time(lcdf$issue_d, "myd") <<---we should not do this, since issue_d is already a date type variable
 
# we can use the lubridate functions to precisely handle date-times durations
lcdf$borrHistory <- as.duration(lcdf$earliest_cr_line %--% lcdf$issue_d  ) / dyears(1)


#Another new attribute: ratio of openAccounts to totalAccounts
lcdf$openAccRatio <- lcdf$open_acc / lcdf$total_acc



#does LC-assigned loan grade vary by borrHistory?
lcdf %>% group_by(grade) %>% summarise(avgBorrHist=mean(borrHistory))

head(lcdf$borrHistory)
head(lcdf$openAccRatio)
#some additional analyses.......(your own)

summary(lcdf[c("propSatisBankcardAccts", "borrHistory","openAccRatio")])


#Checking LC-assigned loan grade variation by borrHistory
lcdf %>% group_by(grade) %>% summarise(avgBorrHist=mean(borrHistory))
```




Converting character variables
```{r}
#Take a look at the variables in the data-set -- are there any variable type changes you want to consider?
glimpse(lcdf)

#  notice that there are a few character type variables - grade, sub_grade, verification_status,....
#   We can  convert all of these to factor
lcdf <- lcdf %>% mutate_if(is.character, as.factor)

```




```{r}
############################################################################
#Q2.(b)
#missing values


#We can use the is.na(x) function to check for 'NA' or missing values in variable x
#   Returns a vector of True/False values based on whether the corresponding values in x is NA


#Drop variables with all empty values
lcdf <- lcdf %>% select_if(function(x){ ! all(is.na(x)) } )
      #  all(is.na(x)) will evaluate to True if all the values in x are missing.
      #  So we keep those variables x which do NOT have all values missing
 # How many variables were dropped ?  You can check by dim(lcdf), before and after this command 


#Of the columns remaining, names of columns with missing values
names(lcdf)[colSums(is.na(lcdf)) > 0]
    # colSums ( is.na( lcdf ) ) returns the total number of True (i.e. NA) values in each column of lcdf
    # We then get the names of these columns


#missing value proportions in each column
colMeans(is.na(lcdf))
# or, get only those columns where there are missing values
colMeans(is.na(lcdf))[colMeans(is.na(lcdf))>0]


#Are there same number of missing values in a set of attributes, and might there be a reason for this?
#How does this inform your handling of missing values?


#Consider open_acc_6m, which has 97% missing
summary(as.factor(lcdf$open_acc_6m))    # shows the counts by different values of the variable
table(lcdf$open_acc_6m)  #gives the same output  -- but it does not show the NAs

# We can replace missing values in a variable with
#      replace_na( variable, "value for missing")     
table( replace_na( as.character(lcdf$open_acc_6m), "missing") )   # shows the 'missing' values
table( lcdf$loan_status, replace_na( as.character(lcdf$open_acc_6m), "missing") ) # shows counts by loan_status at different values of the variable

#to get a bar-plot of these
cc<-table( lcdf$loan_status, replace_na( as.character(lcdf$open_acc_6m), "missing") )
barplot(cc, col=c("darkblue","red"),legend = rownames(cc))  # here, one bar dominates others
# For a better display, we can get proportion of ChargedOff as cc[1,]/(cc[2,]+cc[1,]).  Then to plot this..
barplot(cc[1,]/(cc[2,]+cc[1,]),  ylab = "prop ChargedOff", main="Prop ChargedOff by open_acc_6m")




#Consider the "mths_since_" variables -- what do they represent (see data dictionary)
# Are the missing values here due to zeros; or due to no known values in the period considered (then the actual value would be larger than the max value)? Or are are they really unknown?

#  Variable mths_since_last_record has more than 80% values missing
cc<-table( lcdf$loan_status, replace_na( as.character(lcdf$mths_since_last_record), "missing") )
cc[1,]/(cc[2,]+cc[1,])
# Is the proportion of defaults for 'missing' similar to the large/small values of the variable?  If they do not relate well to larger values, than we should not assume that missings are for values higher than the max.
#If a very large proportion of values is really unknown, may be better to not include this variable in a model?



#For mths_since_last_delinq, which has around 50% values missing 
cc<-table( lcdf$loan_status, replace_na( as.character(lcdf$mths_since_last_delinq), "missing") )
cc[1,]/(cc[2,]+cc[1,])
   #Here, is there a pattern of higher defaults for examples which have more recent delinquencies?  If so, we should try to retain this variable, and find a way to reasonably handle the missing values.
  


#For mths_since_recent_inq, which has around 10% values missing
cc<-table( lcdf$loan_status, replace_na( as.character(lcdf$mths_since_recent_inq), "missing") )
cc[1,]/(cc[2,]+cc[1,])
    # Here,the proportion of defaults for missing values seem similar to the larger values of the variable -- so, may be replace the missings with a large value ?




#Suppose you decide to remove variables which have more than 60% missing values
nm<-names(lcdf)[colMeans(is.na(lcdf))>0.6]
lcdf <- lcdf %>% select(-all_of(nm))




#Impute missing values for remaining variables which have missing values
# - first get the columns with missing values
colMeans(is.na(lcdf))[colMeans(is.na(lcdf))>0]

#summary of data in these columns
nm<- names(lcdf)[colSums(is.na(lcdf))>0]
summary(lcdf[, nm])


#Question -- considering DT based models, can we retain variables which have some (not too many) missing values ?


#Suppose we want to replace the missing values for variables where there are a larger number of missings, and where this seems reasonable (what is your logic for this?)

#For bc_open_to_buy, suppose we want to replace the missing values by the median
#  -- we will try this out and put results in a temporary dataset lcx, with the attributes that have missing values
lcx <-lcdf[, c(nm)]
lcx<- lcx %>% replace_na(list(bc_open_to_buy=median(lcx$bc_open_to_buy, na.rm=TRUE)))


#Similarly for the other variables
#After trying this out on the temporary dataframe lcx, if we are sure this is what we want, we can now  replace the missing values on the lcdf dataset

lcdf<- lcdf %>% replace_na(list(mths_since_last_delinq=-500, bc_open_to_buy=median(lcdf$bc_open_to_buy, na.rm=TRUE), mo_sin_old_il_acct=1000, mths_since_recent_bc=1000, mths_since_recent_inq=50, num_tl_120dpd_2m = median(lcdf$num_tl_120dpd_2m, na.rm=TRUE),percent_bc_gt_75 = median(lcdf$percent_bc_gt_75, na.rm=TRUE), bc_util=median(lcdf$bc_util, na.rm=TRUE) ))
  # Check that the replacement values for missings are reasonable - we should be able to explain why we are doing this.


#Has this addressed all missing values?
colMeans(is.na(lcdf))[colMeans(is.na(lcdf))>0]
  # we did not replace missings for all attributes - will this be ok for DT based models which we will develop in the next phase?


#Variables with missing values
nm<-names(lcdf)[colMeans(is.na(lcdf))>0]
glimpse(lcdf %>% select(nm))
   #we notice that these are all numeric variables  -- replace by the median values?

#To replace the few missing values in a column by the column median values
# -- Try this before making changes in lcdf 
lcx <- lcdf  #copy to lcx
lcx<- lcx %>% mutate_if(is.numeric,  ~ifelse(is.na(.x), median(.x, na.rm = TRUE), .x))
     # if any column has  missing values, replace with median value in that column

#If this works, do the same in lcdf
#lcdf<- lcdf %>% mutate_if(is.numeric,  ~ifelse(is.na(.x), median(.x, na.rm = TRUE), .x))


dim(lcdf)  #how many variables left 

```

############################################################################




Drop some variables for potential leakage, others
```{r}
#Q.2 (c)
#Drop some variable/columns which are not useful or which we will not use in developing predictive models
#Also drop variables those which will cause 'leakage'  <--IMPORTANT 

#Identify the variables you want to remove
varsToRemove = c('funded_amnt_inv', 'term', 'emp_title', 'pymnt_plan', 'earliest_cr_line', 'title', 'zip_code', 'addr_state', 'out_prncp', 'out_prncp_inv', 'total_pymnt_inv', 'total_rec_prncp', 'total_rec_int', 'total_rec_late_fee', 'recoveries', 'collection_recovery_fee', 'last_credit_pull_d', 'policy_code', 'disbursement_method', 'debt_settlement_flag',  'settlement_term', 'application_type')

lcdf <- lcdf %>% select(-all_of(varsToRemove)) 

#Drop all the variables with names starting with "hardship"
lcdf <- lcdf %>% select(-starts_with("hardship"))

#similarly, all variable starting with "settlement"
lcdf <- lcdf %>% select(-starts_with("settlement"))

#removing additional variables which are not required in the analysis
varsToRemove2 <- c("last_pymnt_d", "last_pymnt_amnt", "issue_d","next_pymnt_d","deferral_term","payment_plan_start_date")
lcdf <- lcdf %>% select(-all_of(varsToRemove2))
dim(lcdf)
  

```




```{r}
###############################################################################################################
#Q.3

#Univariate analyses - which variables are individually predictive of the outcome ?
#Considering a single variable model to predict loan_status, what could be a measure of performance?  AUC? 
#For a univariate model with a variable, say, x1, what should we consider as the model 'score' for predicting loan_status? 
#Can we take the values of x1 as the score for a model y_hat=f(x1) ? 

#Using this approximate approach, we can then compute the AUC for each variable




library(pROC) #this package has a function auc(..) which we can readily use

#We will use the function auc(response, prediction) which returns the AUC value for the specified predictor variable, and considering the response variable as the dependent. 
#   Make sure you understand how this works.

# For example:
auc(response=lcdf$loan_status, lcdf$loan_amnt)
 # returns the auc value for loan_amt as the single predictor for loan_status

#In the auc(..) function, the prediction variable has to be numeric ('score') - otherwise, how would it calculate the AUC (think about how auc is calculated). 
# For a factor variable, we can consider the factor levels as numbers:
auc(response=lcdf$loan_status, as.numeric(lcdf$emp_length))


# There may be a few date type variables in the data - we will ignore these here.  
# (Data variables can be handled by converting to days-since variables) 



#How would you calculate AUC this for all variables in the dataset?
# Rather than call the function individually for each variable, we can use the sapply(..) function.
#  - look up how the sapply function works.  Similar to the apply() function.


# For the numeric variables:
aucsNum<-sapply(lcdf %>% select_if(is.numeric), auc, response=lcdf$loan_status)
  #Please make sure we understand what is happening here.  How does sapply work?


#Or considering both numeric and factor variables:
aucAll<- sapply(lcdf %>% mutate_if(is.factor, as.numeric) %>% select_if(is.numeric), auc, response=lcdf$loan_status) 
#aucAll<- sapply(lcdf %>% mutate_if(is.factor, as.numeric) %>% select_if(is.numeric), pROC::auc, response=lcdf$loan_status)



#To determine which variables have auc > 0.5
aucAll[aucAll>0.5]

#Or, we can use the tidy(..) function from the broom package - which converts the 'messy' output into a tidy form as a tibble
library(broom)

tidy(aucAll[aucAll > 0.5]) %>% view()

# or  in any range of values like, tidy(aucAll[aucAll >=0.5 & aucAll < 0.6])
# or in sorted order
tidy(aucAll) %>% arrange(desc(aucAll))

  #Do you notice any of the variables to have a very high AUC -- can indicate leakage?
  # Example, actualReturn, actualTerm are in the data - we have kept these because they will be useful for evaluating performance of models.  
   # Will need to make sure these are not included in building the models

```




Split the data into trn, text subsets
```{r}
###############################################################################################################
#Q.4


TRNPROP = 0.5  #proportion of examples in the training sample

nr<-nrow(lcdf)
trnIndex<- sample(1:nr, size = round(TRNPROP * nr), replace=FALSE)

lcdfTrn <- lcdf[trnIndex, ]
lcdfTst <- lcdf[-trnIndex, ]

```





DT models using rpart
```{r}
###############################################################################################################
#Q.5


#Do you want to use all the variables in the dataset as predictors ?
#Take a look at teh data
glimpse(lcdf)

#Are are some variable you want to exclude  - due to leakage, or other reasons?
#  What about variables like actualTerm, actualReturn, ... which you calculated?
#       These will be useful in performance assessment, but should not be used in building the model.
#Are there any data variables which you may not want to use in developing the model?


varsOmit <- c('actualTerm', 'actualReturn', 'annRet', 'total_pymnt')  #are there others?


library(rpart)

#Check of the target, loan_status, is a factor variable -- if not, convert to  a factor variable
#lcdf$loan_status <- factor(lcdf$loan_status, levels=c("Fully Paid", "Charged Off"))


lcDT1 <- rpart(loan_status ~., data=lcdfTrn %>% select(-all_of(varsOmit)), method="class", parms = list(split = "information"), control = rpart.control(minsplit = 30))
printcp(lcDT1)  #reasonable ?  (If the tree does not grow at all, maybe set a lower value of cp?)

#variable importance
lcDT1$variable.importance
  # Does this look reasonable?  Any leakage causing variables can show up as highly important !!
  #  Make sure you remove any leakage variables (include in varsOmit above)


lcDT1 <- rpart(loan_status ~., data=lcdfTrn %>% select(-all_of(varsOmit)), method="class", parms = list(split = "information"), control = rpart.control(cp=0.0001, minsplit = 50))


#Do we want to prune the tree -- check for performance with different cp levels
printcp(lcDT1)
lcDT1p<- prune.rpart(lcDT1, cp=0.0003)   
     #Note: this value of cp used here is just as an example. You should select the best cp value based on rpart cpTable 

#......

#Training the model considering a more balanced training dataset?
#Use the 'prior' parameters -- to account for unbalanced training data
#The 'prior' parameter can be used to specify the distribution of examples across classes.  By default, the prior is taken from the dataset
#For rpart to consider a balanced distribution:
lcDT1b <- rpart(loan_status ~., data=lcdfTrn %>% select(-all_of(varsOmit)), 
               method="class", parms = list(split = "gini", prior=c(0.5, 0.5)), 
               control = rpart.control(cp=0.0, minsplit = 20, minbucket = 10, maxdepth = 20,  xval=10) )

#find best cp and prune
```


Performance evaluation
```{r}
#Evaluate performance
predTrn=predict(lcDT1,lcdfTrn, type='class')
table(pred = predTrn, true=lcdfTrn$loan_status)
mean(predTrn == lcdfTrn$loan_status)
table(pred = predict(lcDT1,lcdfTst, type='class'), true=lcdfTst$loan_status)
mean(predict(lcDT1,lcdfTst, type='class') ==lcdfTst$loan_status)

#With a different classification threshold
CTHRESH=0.3
predProbTrn=predict(lcDT1,lcdfTrn, type='prob')
predTrnCT = ifelse(predProbTrn[, 'Charged Off'] > CTHRESH, 'Charged Off', 'Fully Paid')
table(predTrnCT , true=lcdfTrn$loan_status)
# Or, to set the predTrnCT values as factors, and then get the confusion matrix
table(predictions=factor(predTrnCT, levels=c("Fully Paid", "Charged Off")), actuals=lcdfTrn$loan_status)



#Or you can use the confusionMatrix function from the caret package
library(caret)
confusionMatrix(predTrn, lcdfTrn$loan_status)
    #if you get an error saying that the 'e1071' package is required, 
    # you should install and load that too
#Notice that the output says 
#   'Positive' class: Fully Paid
#So,the confusionMatrix based performance measures are based 
#  on the "Fully Paid" class as the class of interest.
# If you want to get performance measure for "Charged Off", use 
#    the positive- paremeter
confusionMatrix(predTrn, lcdfTrn$loan_status, positive="Charged Off")

#For the test data?


#ROC plot
library(ROCR)

score=predict(lcDT1,lcdfTst, type="prob")[,"Charged Off"]
pred=prediction(score, lcdfTst$loan_status, label.ordering = c("Fully Paid", "Charged Off"))
    #label.ordering here specifies the 'negative', 'positive' class labels   

#ROC curve
aucPerf <-performance(pred, "tpr", "fpr")
plot(aucPerf)
abline(a=0, b= 1)

#AUC value
aucPerf=performance(pred, "auc")
aucPerf@y.values


#Lift curve
liftPerf <-performance(pred, "lift", "rpp")
plot(liftPerf)

###############################################################################################################
```









###############################################################################################################

```{r}
#Q6.(a)

#Random forest models

library(ranger)

rfModel1 <- ranger(loan_status ~., data=lcdfTrn[complete.cases(lcdfTrn),] %>%  select(-all_of(varsOmit)), num.trees = 200, importance='permutation', probability = TRUE)

#variable importance
#vimp_rfGp<-importance(rfModel1)
#vimp_rfGp %>% view()
rfModel1$variable.importance.local
importance

#Get the predictions -- look into the returned object
scoreTrn <- predict(rfModel1,lcdfTrn[complete.cases(lcdfTrn),])
head(scoreTrn$predictions)

#classification performance , at specific threshold 
table(pred = scoreTrn$predictions[, "Fully Paid"] > 0.7, actual=lcdfTrn[complete.cases(lcdfTrn),]$loan_status)

scoreTst <- predict(rfModel1,lcdfTst[complete.cases(lcdfTst),])
table(pred = scoreTst$predictions[, "Fully Paid"] > 0.7, actual=lcdfTst[complete.cases(lcdfTst),]$loan_status)


#ROC curve, AUC
pred=prediction(scoreTrn$predictions[, "Fully Paid"], lcdfTrn[complete.cases(lcdfTrn),]$loan_status, label.ordering = c("Charged Off","Fully Paid" ))  #ROC curve
aucPerf <-performance(pred, "tpr", "fpr")
plot(aucPerf)
abline(a=0, b= 1)

#AUC value
aucPerf=performance(pred, "auc")
sprintf("AUC: %f", aucPerf@y.values)


#Or call the performance function defined above
fnROCPerformance(predict(rfModel1,lcdfTst[complete.cases(lcdfTst),])$predictions[,"Fully Paid"], dat=lcdfTst[complete.cases(lcdfTst),])

#for decile defaults-lift performance
fnDecileLiftsPerformance_defaults( predict(rfModel1,lcdfTrn[complete.cases(lcdfTrn),])$predictions[,"Charged Off"], lcdfTrn[complete.cases(lcdfTrn),]  )
     #Note- this function calculates lifts for the minority class - so score should be prob of "charged off'

#for decile returns performance
fnDecileReturnsPerformance( predict(rfModel1,lcdfTrn[complete.cases(lcdfTrn),])$predictions[,"Fully Paid"], lcdfTrn[complete.cases(lcdfTrn),]  )
     #do you understand why we  provide scores for "Fully Paid" here?




#Different parameters for random forest - for example, if the default model is seen to overfit
rfModel2 <- ranger(loan_status ~., data=lcdfTrn[complete.cases(lcdfTrn),] %>%  select(-all_of(varsOmit)),
                   num.trees =500, probability = TRUE, min.node.size = 50, max.depth = 15)
#     min.node.size,  max.depth
#     look up https://www.rdocumentation.org/packages/ranger/versions/0.13.1/topics/ranger


rfModel3 <- ranger(loan_status ~., data=lcdfTrn[complete.cases(lcdfTrn),] %>%  select(-all_of(varsOmit)), num.trees =500, class.weights = c(6,1))
#     class.weights
#        "Weights for the outcome classes (in order of the factor levels) in the splitting rule (cost sensitive learning). For classification the weights are also applied in the majority vote in terminal nodes".
#     look up https://www.rdocumentation.org/packages/ranger/versions/0.13.1/topics/ranger
```
###############################################################################################################



```{r}
#Q6.(b)

#XGboost with cross verification
#XGBoost For Loan Status
library (xgboost)

outcome_index = which(colnames(lcdfTrn)=='loan_status')


#xgbParamGrid %>% view()

for(i in 1:nrow(xgbParamGrid)) {
xgb_tune<- xgboost(data = train_x, label = train_y_int,  objective = "reg:squarederror", nrounds=50, 
eta=xgbParamGrid$eta[i],
max_depth=xgbParamGrid$max_depth[i], 
early_stopping_rounds = 10)
xgbParamGrid$bestTree[i] <- xgb_tune$evaluation_log[xgb_tune$best_iteration]$iter
xgbParamGrid$bestPerf[i] <- xgb_tune$evaluation_log[xgb_tune$best_iteration]$train_rmse
}
#xgbParamGrid %>% view()

## Trainig Data with Best Parameters
xgb_lsM1 <- xgboost(data = train_x, label = train_y_int,max.depth = 5, eta = 0.01, nthread = 2,nrounds = 50, objective = "binary:logistic")

##predicted probability of loan being paid back

xpredTst<-predict(xgb_lsM1, test_x)
scoreTst_xgb_ls <- lcdfTst %>% select(grade, loan_status, actualReturn, actualTerm, int_rate) %>% mutate(score=xpredTst)
scoreTst_xgb_ls <- scoreTst_xgb_ls %>% mutate(tile=ntile(-score, 10))
scoreTst_xgb_ls %>% group_by(tile) %>% summarise(count=n(), avgSc=mean(score), numDefaults=sum(loan_status=="Fully Paid"),
avgActRet=mean(actualReturn), minRet=min(actualReturn), maxRet=max(actualReturn), avgTer=mean(actualTerm), totA=sum(grade=="A"),
totB=sum(grade=="B" ), totC=sum(grade=="C"), totD=sum(grade=="D"), totE=sum(grade=="E"), totF=sum(grade=="F") )

pred_xgb <- prediction(xpredTst, test_y_int)

# Calculate AUC
auc_xgb <- performance(pred_xgb, measure = "auc")
auc_xgb <- auc_xgb@y.values[[1]]

# Plot ROC curve
roc_xgb <- performance(pred_xgb, measure = "tpr", x.measure = "fpr")
plot(roc_xgb)
abline(a = 0, b = 1)

# Print AUC value
auc_xgb

#Needs all data to be numeric -- so we convert categorical (i.e. factor) variables using one-hot encoding – multiple ways to do this
# use the dummyVars function in the 'caret' package to convert factor variables to multiple dummy-variables
fdum <- dummyVars ( ~. , data=lcdf %>% select(-loan_status)) #do not include loan_status for this
dxlcdf <- predict ( fdum, lcdf)
# for loan_status, check levels and convert to dummy vars and keep the class label of interest
#levels(lcdf$loan_status)
dylcdf <- class2ind(lcdf$loan_status, drop2nd = FALSE)
# and then decide which one to keep
colcdf <- dylcdf [ , 1] #(fullyPaid or chargedOff as label of interest)
#Training, test subsets
dxlcdfTrn <- dxlcdf[trnIndex,]
colcdfTrn <- colcdf[trnIndex]
dxlcdfTst <- dxlcdf[-trnIndex,]
colcdfTst <- colcdf[-trnIndex]
dTrn <- xgb.DMatrix( subset(dxlcdfTrn, select = -c( actualTerm, actualReturn, total_pymnt)), label=colcdfTrn)
dTst <- xgb.DMatrix( subset( dxlcdfTst, select = -c( actualTerm, actualReturn, total_pymnt)), label=colcdfTst)

xgbWatchlist <- list(train = dTrn, eval = dTst)
#we can watch the progress of learning thru performance on these datasets
#list of parameters for the xgboost model development functions
xgbParam <- list (
max_depth = 5, eta = 0.01,
objective = "binary:logistic",
eval_metric="error", eval_metric = "auc")
#can specify which evaluation metrics we want to watch
xgb_lsM1 <- xgb.train( xgbParam, dTrn, nrounds = 500,
xgbWatchlist, early_stopping_rounds = 10 )

#Cross-validation
xgbParam <- list (
max_depth = 3, eta = 0.1,
objective = "binary:logistic",
eval_metric="error", eval_metric = "auc")
xgb_lscv <- xgb.cv( xgbParam, dTrn, nrounds = 500, nfold=5, early_stopping_rounds = 10 )
#best iteration
xgb_lscv$best_iteration
# or for the best iteration based on performance measure (among those specified in xgbParam)
best_cvIter <- which.max ( xgb_lscv$evaluation_log$test_auc_mean)
#which.min(xgb_lscv$evaluation_log$test_error_mean)
#learn the best model without cross-validation
xgb_lsbest <- xgb.train( xgbParam, dTrn, nrounds = xgb_lscv$best_iteration )
#variable importance
xgb.importance(model = xgb_lsbest) %>% view()


#compare

xgbParam <- list (
eta = 0.01,
objective = "binary:logistic",
eval_metric="error", eval_metric = "auc")

xgb_lsM1 <- xgb.train( xgbParam, dTrn, nrounds = 500,
xgbWatchlist, early_stopping_rounds = 10 )

xgbParam <- list (
 eta = 0.01,
 objective = "binary:logistic",
 eval_metric="auc", eval_metric = "error")

xgb_lsM1 <- xgb.train( xgbParam, dTrn, nrounds = 500,
xgbWatchlist, early_stopping_rounds = 10)
```





Write functions which we can easily call (rather than write multiple lines of code) for performance evaluation
```{r}

#ROC curve and AUC value
fnROCPerformance <- function(scores, dat) {  #Note the label-ordering - so, scores should be prob of 'Fully Paid'
    pred=prediction(scores, dat$loan_status, label.ordering = c("Charged Off", "Fully Paid" ))

  #ROC curve
  aucPerf <-performance(pred, "tpr", "fpr")
  plot(aucPerf)
  abline(a=0, b= 1)

  #AUC value
  aucPerf=performance(pred, "auc")
  sprintf("AUC: %f", aucPerf@y.values)
}


#decile lift performance, for minority class (Charged Off") 
#   the 'score' parameter should gice 'prob' of loan_status == 'Charged Off'
fnDecileLiftsPerformance_defaults  <- function( scores, dat) {  #score is for loan_status=='Charged Off'
  totDefRate= sum(dat$loan_status=="Charged Off")/nrow(dat)
  decPerf <- data.frame(scores)
  decPerf <- cbind(decPerf, status=dat$loan_status, grade=dat$grade)
  decPerf <- decPerf %>% mutate(decile = ntile(-scores, 10))
  decPerf<-  decPerf  %>% group_by(decile) %>% summarise ( 
    count=n(), numDefaults=sum(status=="Charged Off"), defaultRate=numDefaults/count,
    totA=sum(grade=="A"),totB=sum(grade=="B" ), totC=sum(grade=="C"), totD=sum(grade=="D"),
    totE=sum(grade=="E"),totF=sum(grade=="F") )
  decPerf$cumDefaults=cumsum(decPerf$numDefaults)                      
  decPerf$cumDefaultRate=decPerf$cumDefaults/cumsum(decPerf$count)                      
  decPerf$cumDefaultLift<- decPerf$cumDefaultRate/(sum(decPerf$numDefaults)/sum(decPerf$count))
  
  print(decPerf)
}


#Returns performance by deciles
fnDecileReturnsPerformance <- function( scores, dat) {
  decRetPerf <- data.frame(scores)
  decRetPerf <- cbind(decRetPerf, status=dat$loan_status, grade=dat$grade, actRet=dat$actualReturn, actTerm = dat$actualTerm)
  decRetPerf <- decRetPerf %>% mutate(decile = ntile(-scores, 10))
  decRetPerf %>% group_by(decile) %>% summarise (
    count=n(), numDefaults=sum(status=="Charged Off"), avgActRet=mean(actRet), minRet=min(actRet), maxRet=max(actRet),
    avgTer=mean(actTerm), totA=sum(grade=="A"), totB=sum(grade=="B" ), totC=sum(grade=="C"), totD=sum(grade=="D"),
    totE=sum(grade=="E"), totF=sum(grade=="F") )
}


  
```
#QUESTION 8 - 

```{r}
#removing any rows with missing values
lcdfTrn <- lcdfTrn[complete.cases(lcdfTrn),]
lcdfTst <- lcdfTst[complete.cases(lcdfTst),]

#creating a random forest model called rfModel_Ret using the ranger() function
rfModel_Ret <- ranger(actualReturn ~., data=subset(lcdfTrn, select=-c(annRet, actualTerm, loan_status)), num.trees =200,importance='permutation')

#making the predictions using the random forest model that was trained in the previous line of code, and to evaluate the model's performance on both the training and test data sets
rfPredRet_trn<- predict(rfModel_Ret, lcdfTrn)
rfPredRet_tst <- predict(rfModel_Ret, lcdfTst)
sqrt( mean( (rfPredRet_trn$predictions - lcdfTrn$actualReturn)^2) )
sqrt(mean( ( (predict(rfModel_Ret, lcdfTst))$predictions - lcdfTst$actualReturn)^2))
plot ( (predict(rfModel_Ret, lcdfTrn))$predictions, lcdfTrn$actualReturn)
plot ( (predict(rfModel_Ret, lcdfTst))$predictions, lcdfTst$actualReturn)


#Evaluating performance by deciles

# Training Set
predRetRF_Trn <- lcdfTrn %>% select(grade, loan_status, actualReturn, actualTerm, int_rate) %>% mutate(predRet=(predict(rfModel_Ret, lcdfTrn))$predictions)
predRetRF_Trn <- predRetRF_Trn %>% mutate(tile=ntile(-predRet, 10))

predRetRF_Trn %>% group_by(tile) %>% summarise(count=n(), avgpredRet=mean(predRet), numDefaults=sum(loan_status=="Charged Off"),avgActRet=mean(actualReturn), minRet=min(actualReturn), maxRet=max(actualReturn), avgTer=mean(actualTerm), totA=sum(grade=="A"),totB=sum(grade=="B" ), totC=sum(grade=="C"), totD=sum(grade=="D"), totE=sum(grade=="E"), totF=sum(grade=="F"), totG=sum(grade=="G") )

# Testing Set
predRetRF_Tst <- lcdfTst %>% select(grade, loan_status, actualReturn, actualTerm, int_rate) %>% mutate(predRet=(predict(rfModel_Ret, lcdfTst))$predictions)
predRetRF_Tst <- predRetRF_Tst %>% mutate(tile=ntile(-predRet, 10))

predRetRF_Tst %>% group_by(tile) %>% summarise(count=n(), avgpredRet=mean(predRet), numDefaults=sum(loan_status=="Charged Off"),avgActRet=mean(actualReturn), minRet=min(actualReturn), maxRet=max(actualReturn), avgTer=mean(actualTerm), totA=sum(grade=="A"),totB=sum(grade=="B" ), totC=sum(grade=="C"), totD=sum(grade=="D"), totE=sum(grade=="E"), totF=sum(grade=="F"), totG=sum(grade=="G") )

```
```{r}
#install.packages('glmnet')
library(glmnet)
xD <- lcdfTrn %>% select(-loan_status, -actualTerm, -annRet, -actualReturn)
glmRet_cv <- cv.glmnet( data.matrix(xD), lcdfTrn$actualReturn, family="gaussian")


predRetGLM_Trn <- lcdfTrn %>% select(grade, loan_status, actualReturn, actualTerm, int_rate) %>% mutate(predRet = predict(glmRet_cv, data.matrix(lcdfTrn %>% select(-loan_status, -actualTerm, -annRet, -actualReturn)),s="lambda.min" ) )
predRetGLM_Trn <- predRetGLM_Trn %>% mutate(tile=ntile(-predRet, 10))

predRetGLM_Trn %>% group_by(tile) %>% summarise(count=n(), avgpredRet=mean(predRet), numDefaults=sum(loan_status=="Charged Off"),
                                                avgActRet=mean(actualReturn), minRet=min(actualReturn), maxRet=max(actualReturn), avgTer=mean(actualTerm), totA=sum(grade=="A"),
                                                totB=sum(grade=="B" ), totC=sum(grade=="C"), totD=sum(grade=="D"), totE=sum(grade=="E"), totF=sum(grade=="F"), totG=sum(grade=="G") )


predRetGLM_Tst <- lcdfTst %>% select(grade, loan_status, actualReturn, actualTerm, int_rate) %>% mutate(predRet = predict(glmRet_cv, data.matrix(lcdfTst %>% select(-loan_status, -actualTerm, -annRet, -actualReturn)),s="lambda.min" ))

predRetGLM_Tst <- predRetGLM_Tst %>% mutate(tile=ntile(-predRet, 10))
predRetGLM_Tst %>% group_by(tile) %>% summarise(count=n(), avgpredRet=mean(predRet), numDefaults=sum(loan_status=="Charged Off"),
                                                avgActRet=mean(actualReturn), minRet=min(actualReturn), maxRet=max(actualReturn), avgTer=mean(actualTerm), totA=sum(grade=="A"),
                                                totB=sum(grade=="B" ), totC=sum(grade=="C"), totD=sum(grade=="D"), totE=sum(grade=="E"), totF=sum(grade=="F"), totG=sum(grade=="G") )

#RMSE For Training Data and Testing Data
sqrt(mean((predRetGLM_Trn$predRet - lcdfTrn$actualReturn)^2))
sqrt(mean(( predRetGLM_Tst$predRet - lcdfTst$actualReturn)^2))
plot (predRetGLM_Trn$predRet, lcdfTrn$actualReturn)
plot (predRetGLM_Tst$predRet, lcdfTst$actualReturn)

```
```{r}
library (xgboost)
lcdfTrn <- lcdfTrn[complete.cases(lcdfTrn),]
lcdfTst <- lcdfTst[complete.cases(lcdfTst),]
outcome_index_ret = which(colnames(lcdfTrn)=='actualReturn')

train_x_ret = data.matrix(lcdfTrn[, -outcome_index_ret])
train_y_ret = data.matrix(lcdfTrn[,outcome_index_ret])

dim(train_y_ret)

test_x_ret = data.matrix(lcdfTst[, -outcome_index_ret])
test_y_ret = data.matrix(lcdfTst[, outcome_index_ret])
train_y_int_ret = as.numeric(train_y_ret == "Fully Paid")
test_y_int_ret = as.numeric(test_y_ret == "Fully Paid")


xgbParamGrid <- expand.grid(
  max_depth = c(2, 5,10,20),
  eta = c(0.001, 0.01, 0.1,0.5,1) )

#xgbParamGrid %>% view()



for(i in 1:nrow(xgbParamGrid)) {
  xgb_tune_ret<- xgboost(data = train_x_ret, label = train_y_ret,  objective = "reg:squarederror", nrounds=50, 
                         eta=xgbParamGrid$eta[i],
                         max_depth=xgbParamGrid$max_depth[i], 
                         early_stopping_rounds = 10)
  xgbParamGrid$bestTree[i] <- xgb_tune_ret$evaluation_log[xgb_tune_ret$best_iteration]$iter
  xgbParamGrid$bestPerf[i] <- xgb_tune_ret$evaluation_log[xgb_tune_ret$best_iteration]$train_rmse
}
View(xgbParamGrid)
#xgbParamGrid %>% view()

## Trainig Data with Best Parameters
xgb_lsM2 <- xgboost(data = train_x_ret, label = train_y_ret,max.depth = 5, eta = 1, nthread = 2,nrounds = 50, objective = "reg:squarederror")


#Performance by deciles

# Training Set
library(dplyr)
predRetXGB_Trn <- lcdfTrn %>% select(grade, loan_status, actualReturn,actualTerm,int_rate) %>% mutate(predRet=(predict(xgb_lsM2, train_x_ret)))
predRetXGB_Trn <- predRetXGB_Trn %>% mutate(tile=ntile(-predRet, 10))

predRetXGB_Trn %>% group_by(tile) %>% summarise(count=n(), avgpredRet=mean(predRet), numDefaults=sum(loan_status=="Charged Off"),avgActRet=mean(actualReturn), minRet=min(actualReturn), maxRet=max(actualReturn), avgTer=mean(actualTerm), totA=sum(grade=="A"),totB=sum(grade=="B" ), totC=sum(grade=="C"), totD=sum(grade=="D"), totE=sum(grade=="E"), totF=sum(grade=="F"), totG=sum(grade=="G") )

# Testing Set
predRetXGB_Tst <- lcdfTst %>% select(grade, loan_status, actualReturn, actualTerm, int_rate) %>% mutate(predRet=(predict(xgb_lsM2, test_x_ret)))
predRetXGB_Tst <- predRetXGB_Tst %>% mutate(tile=ntile(-predRet, 10))

predRetXGB_Tst %>% group_by(tile) %>% summarise(count=n(), avgpredRet=mean(predRet), numDefaults=sum(loan_status=="Charged Off"),avgActRet=mean(actualReturn), minRet=min(actualReturn), maxRet=max(actualReturn), avgTer=mean(actualTerm), totA=sum(grade=="A"),totB=sum(grade=="B" ), totC=sum(grade=="C"), totD=sum(grade=="D"), totE=sum(grade=="E"), totF=sum(grade=="F"), totG=sum(grade=="G") )


#RMSE For Training Data and Testing Data
sqrt(mean(((predict(xgb_lsM2, train_x_ret)) - lcdfTrn$actualReturn)^2))
sqrt(mean(((predict(xgb_lsM2, test_x_ret)) - lcdfTst$actualReturn)^2))
```

